<!DOCTYPE html>
<html lang="en">
<!-- Beautiful Jekyll 6.0.1 | Copyright Dean Attali 2023 -->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

  

  

  <title>The Schrödinger equation | Even Nordhagen</title>

  
  
  <meta name="author" content="Even Nordhagen">
  

  <meta name="description" content="solved with a machine learning approach">

  

  
  <meta name="keywords" content="Even Marius Nordhagen, Nordhagen, Even Nordhagen, machine learning, friction, molecular dynamics simulations, weather models">
  

  
  <link rel="alternate" type="application/rss+xml" title="Even Nordhagen" href="/feed.xml">
  

  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GZ6Q8NX2RD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-GZ6Q8NX2RD');
</script>


  

  

  

  
<script type="text/javascript">
  MathJax = {
    options: {
      skipHtmlTags: [
        'script', 'noscript', 'style', 'textarea', 'pre', 'code'
      ]
    }
  };
</script>
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



  
    
      
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">


    
      
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">


    
  

  
    
      <link rel="stylesheet" href="/assets/css/bootstrap-social.css">
    
      <link rel="stylesheet" href="/assets/css/beautifuljekyll.css">
    
  

  

  
  
  

  

  
  <meta property="og:site_name" content="Even Nordhagen">
  <meta property="og:title" content="The Schrödinger equation | Even Nordhagen">
  <meta property="og:description" content="solved with a machine learning approach">

  
  <meta property="og:image" content="/assets/img/portrait_nordhagen_machine_learning.jpg">
  

  
  <meta property="og:type" content="website">
  <meta property="og:url" content="/projects/quantumdots/">
  <link rel="canonical" href="/projects/quantumdots/">
  

  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:site" content="@">
  <meta name="twitter:creator" content="@">

  <meta property="twitter:title" content="The Schrödinger equation | Even Nordhagen">
  <meta property="twitter:description" content="solved with a machine learning approach">

  
  <meta name="twitter:image" content="/assets/img/portrait_nordhagen_machine_learning.jpg">
  

  


  

  
  
  <link rel="icon" href="/favicon.ico" />
  

  

</head>


<body>
  


  <nav class="navbar navbar-expand-xl navbar-light fixed-top navbar-custom top-nav-regular"><a class="navbar-brand navbar-brand-logo" href="/"><img alt="Even Nordhagen Logo" src="/assets/img/signature.png"/></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="main-navbar">
    <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="/aboutme">About me</a>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Projects</a>
            <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/projects/friction">Friction modelling</a>
                  <a class="dropdown-item" href="/projects/inversedesign">Inverse design</a>
                  <a class="dropdown-item" href="/projects/quantumdots">Quantum dots</a>
                  <a class="dropdown-item" href="/projects/building-water-model">Water model</a>
            </div>
          </li>
        
          <li class="nav-item">
            <a class="nav-link" href="/publications">Publications</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="/contact">Contact</a>
          </li>
        <li class="nav-item">
          <a class="nav-link" id="nav-search-link" href="#" title="Search">
            <span id="nav-search-icon" class="fa fa-search"></span>
            <span id="nav-search-text">Search</span>
          </a>
        </li></ul>
  </div>

  

  
    <div class="avatar-container">
      <div class="avatar-img-border">
        <a href="/">
          <img alt="Navigation bar avatar" class="avatar-img" src="/assets/img/portrait_nordhagen_machine_learning.jpg" />
        </a>
      </div>
    </div>
  

</nav>



<div id="beautifuljekyll-search-overlay">

  <div id="nav-search-exit" title="Exit search">✕</div>
  <input type="text" id="nav-search-input" placeholder="Search">
  <ul id="search-results-container"></ul>
  
  <script src="https://unpkg.com/simple-jekyll-search@latest/dest/simple-jekyll-search.min.js"></script>
  <script>
    var searchjson = '[ \
       \
        { \
          "title"    : "New Paper Out", \
          "desc"     : "New Paper Out", \
          "category" : "waternucleationVashishtaMonte CarloMetropolisAVBMC", \
          "url"      : "/2025-07-06-avbmc/", \
          "date"     : "July  6, 2025" \
        }, \
       \
        { \
          "title"    : "Langtangen Was Right", \
          "desc"     : "Langtangen Was Right", \
          "category" : "AI boomartificial intelligencemachine learningHans Petter Langtangen", \
          "url"      : "/2025-05-04-ai-reflections/", \
          "date"     : "May  4, 2025" \
        }, \
       \
        { \
          "title"    : "Destination Earth - On-Demand Extremes (DE330)", \
          "desc"     : "Destination Earth - On-Demand Extremes (DE330)", \
          "category" : "Destination EarthDestinEDE330DEODEextreme weather", \
          "url"      : "/2024-12-27-deode/", \
          "date"     : "December 27, 2024" \
        }, \
       \
        { \
          "title"    : "Playing with Europe&#39;s Biggest Supercomputers", \
          "desc"     : "Playing with Europe&#39;s Biggest Supercomputers", \
          "category" : "EuroHPCtier-0LUMILeonardo", \
          "url"      : "/2024-10-27-european-tier-0/", \
          "date"     : "October 27, 2024" \
        }, \
       \
        { \
          "title"    : "Regional Data-Driven Weather Modeling", \
          "desc"     : "Regional Data-Driven Weather Modeling", \
          "category" : "AIFSstretched-grid", \
          "url"      : "/2024-09-12-stretched-grid/", \
          "date"     : "September 12, 2024" \
        }, \
       \
        { \
          "title"    : "Workshop on Large-scale Deep Learning for the Earth System", \
          "desc"     : "Workshop on Large-scale Deep Learning for the Earth System", \
          "category" : "weather predictionmachine learningdata-driven", \
          "url"      : "/2024-09-10-large-scale-deep-learning-earth-system/", \
          "date"     : "September 10, 2024" \
        }, \
       \
        { \
          "title"    : "My first blog post", \
          "desc"     : "My first blog post", \
          "category" : "first post", \
          "url"      : "/2024-09-01-first-post/", \
          "date"     : "September  1, 2024" \
        }, \
       \
       \
        { \
          "title"    : "About me", \
          "desc"     : "About me", \
          "category" : "page", \
          "url"      : "/aboutme/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Building a Flexible Water Model", \
          "desc"     : "Building a Flexible Water Model", \
          "category" : "dissociativewatermolecular dynamicsVashishtagenetic algorithm", \
          "url"      : "/projects/building-water-model/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Contact Me", \
          "desc"     : "Contact Me", \
          "category" : "page", \
          "url"      : "/contact/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Friction modeling", \
          "desc"     : "Friction modeling", \
          "category" : "page", \
          "url"      : "/projects/friction/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Even Nordhagen", \
          "desc"     : "Even Nordhagen", \
          "category" : "page", \
          "url"      : "/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Inverse frictional design", \
          "desc"     : "Inverse frictional design", \
          "category" : "dissociativewatermolecular dynamicsVashishtagenetic algorithm", \
          "url"      : "/projects/inversedesign/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Publications", \
          "desc"     : "Publications", \
          "category" : "page", \
          "url"      : "/publications/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "The Schrödinger equation", \
          "desc"     : "The Schrödinger equation", \
          "category" : "page", \
          "url"      : "/projects/quantumdots/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Software", \
          "desc"     : "Software", \
          "category" : "page", \
          "url"      : "/software/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Tag Index", \
          "desc"     : "Tag Index", \
          "category" : "page", \
          "url"      : "/tags/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Even Nordhagen", \
          "desc"     : "Even Nordhagen", \
          "category" : "page", \
          "url"      : "/page2/", \
          "date"     : "January 1, 1970" \
        } \
       \
    ]';
    searchjson = JSON.parse(searchjson);

    var sjs = SimpleJekyllSearch({
      searchInput: document.getElementById('nav-search-input'),
      resultsContainer: document.getElementById('search-results-container'),
      json: searchjson
    });
  </script>
</div>





  



<header class="header-section ">
<div class="intro-header ">
  
  <div class="container-md">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
        <div class="page-heading">
          <h1>The Schrödinger equation</h1>
          
            
              <hr class="small">
              <span class="page-subheading">solved with a machine learning approach</span>
            
          
          
          
        </div>
      </div>
    </div>
  </div>
  
  
</div>



</header>


<main class=" container-md ">
  <div class="row">
    <div class=" col-xl-8 offset-xl-2 col-lg-10 offset-lg-1 ">
      

      <p><img src="/assets/img/quantum_dots/onebody.png" alt="One-body" class="mx-auto d-block" />
<em>The one-body density determines the probability of finding a particle at a certain distance from another particle. Here, applied on quantum dots with machine learning prediction to the left and classical method to the right</em></p>

\[\hat{\mathcal{H}}\Psi=E\Psi\]

<p>The Schrödinger equation, used to describe quantum mechanical systems such as atoms and sub-atomic systems, is often perceived as the most accurate equation in physics. By solving the time-independent Schrödinger equation presented above, we can in principle get all information about the system it was solved for. However, solving the equation is often a highly non-trivial task, and only systems with up to two objects can be solved with analytical methods, known as the three-body problem. Many sophisticated methods have been developed to find approximate solutions to the equation, but they need to trade-off between accuracy and computational cost. The most accurate methods are very computational intensive, and can only be applied on tiny systems like small atoms.</p>

<p>(insert accuracy as a function of computational cost plot)
<em>Caption</em></p>

<p>To challenge the classical methods, we have developed a machine learning approach to solving the Schrödinger equation. Machine learning is well-suited for this task due to the underlying principles of quantum mechanics:</p>

<p><em>The variational principle ensures that the system energy \(E\) will never be smaller than the ground-state energy, regardless of the choice of the wavefunction \(\Psi\)</em></p>

<p>This important because it means we can optimize \(\Psi\) with respect to minimizing \(E\) in order to find the ground state. And once \(E\) is minimized, we have the ground state wavefunction \(\Psi_0\), which in principle provides all the information about the system.</p>

<p>This idea is not innovative. In fact, the foundation of this methodology, known as variational Monte Carlo (VMC), was laid in the 1950’s and has since been very successful (missing reference). However, the method requires an initial wavefunction guess, or a <em>trial wavefunction</em>, which again requires some insight about the system. Convergence of the method is sensitive to the trial wavefunction, which can be highly non-trivial for complex systems. One way to make the approach more general is to replace the trial wavefunction by a neural network, known for its flexibility (missing reference). The idea was inspired by neural quantum states (missing reference) and FermiNet (missing reference).</p>

<p>For our full paper, please see <a href="https://www.frontiersin.org/articles/10.3389/fphy.2023.1061580"><em>Front. Phys.</em>, 11:1061580</a>.</p>

<h2 id="machine-learning-terminology">Machine learning terminology</h2>
<p>In machine learning terminology, the trial wavefunction, \(\Psi_T\), is our <em>model</em>. It is represented by a neural network, which contains all the variational parameters that are optimized during training. The associated energy, known as the <em>trial energy</em>, \(E\), will be treated as our <em>loss function</em> and is lower bounded by the ground state energy. I have written a <a href="https://evennordhagen.com/2025-05-04-ai-reflections/">blog post</a> about machine learning, components and terminology.</p>

<p>(cool image)
<em>Caption</em>
<img src="/assets/img/building-water-model/dissociative_water.png" alt="Water molecule" class="img-responsive-center" /></p>
<p><em>Real water molecules can react with the surroundings. Most water models do not capture this chemical nature of water</em></p>

<h2 id="methodology">Methodology</h2>
<p>Machine learning is all about optimizing parameters with respect to minimizing a metric, such as the energy. This is typically done with a gradient method:</p>

\[\theta \leftarrow \theta-\nabla_{E}\Delta x.\]

<p>Here, \(\nabla_{E}\) is the gradient of the energy and \(\Delta_x\) is the step length, or the <em>learning rate</em> in machine learning terms. The energy is computed by solving the inner product</p>

\[E=\frac{\langle\Psi|\hat{\mathcal{H}}|\Psi\rangle}{\langle\Psi|\Psi\rangle},\]

<p>which numerically is possible when we know the wave function \(\Psi\). The algorithm for converging towards the correct ground-state wavefunction \(\Psi_0\) is the following:</p>

<ol>
  <li>Initialize the trial wavefunction, \(\Psi_T\), in our case a neural network \(\sim\mathcal{N}(0,\mathbb{I})\)</li>
  <li>Compute \(E\) from the equation above</li>
  <li>Compute \(\partial E/\partial\theta\), the gradient components</li>
  <li>Update \(\Psi\) to minimize the energy</li>
  <li>Repeat 2, 3 and 4 until convergence</li>
</ol>

<p>Computation of the energy and the gradients here is the computationally intensive part, and also the mathematically most involved one. This is not needed to follow this blog post, but if you’re curious, feel free to look into the last section.</p>

<p>(show convergence)
<em>Caption</em></p>

<h2 id="application-quantum-dots">Application: Quantum dots</h2>
<p>This method is general, and can in principle be applied to any quantum mechanical system, such as atoms and molecules. However, the system size is limited by the computational cost of the system energy and gradients, and we are in practice restricted to small systems of a few atoms. As a proof of concept, we apply the methodology to quantum dots, which have natural and cheap to calculate basis functions in the Hermite polynomials. Also, the quantum dots have significant applications in the field of technology.</p>

<p>(show quantum dots)
<em>Caption</em></p>

<h2 id="sampling-the-energy-and-gradients">Sampling the energy and gradients*</h2>
<p>I will try to keep this post easy to read without too many details, but some math is needed to explain how this method works. However, if you are not familiar with quantum mechanics, feel free to skip this section.</p>

<p>This section is about how the system energy \(E_T\) is calculated for a particular function \(Psi_T\), which is done by sampling.</p>

<p>Suppose that we have an initial guess of our function \(\Psi\), denoted by \(\Psi_T\) (trial function). Then, the trial energy is given by</p>

\[E_T=\int\Psi_T^*\hat{\mathcal{H}}\Psi_T d\tau,\]

<p>where \(E_T\geq E_0\) according to the variational principle, with \(E_0\) as the ground-state energy. By defining the local energy as</p>

\[E_L=\frac{1}{\Psi_T}\hat{\mathcal{H}}\Psi_T,\]

<p>we may write</p>

\[E_T=\int P_T E_L d\tau\]

<p>where the probability distribution follows the Born rule:</p>

\[P_T\equiv \Psi_T^*\Psi_T.\]

<p>An important thing to recognize here is that the trial energy $E_T$ is the <em>expectation value</em> of the local energy $E_L$. This means that the system energy can be found by <em>sampling</em> the local energy:</p>

\[E_T=\langle E_L \rangle = \frac{1}{n}\sum_{i=1}^{n}E_L(i).\]

<p>Here, it is important to draw the system samples from the correct probability distribution \(P_T\), which can be done with Metropolis sampling.</p>

<h2 id="optimization-using-machine-learning">Optimization using machine learning</h2>
<p>Once we have calculated the system energy \(E_T\). However, to change \(\Psi_T\) in order to minimize the energy \(E_T\), we need to know how \(E_T\) changes as we change the parameters in \(\Psi_T\), \(\theta\). We need to know \(dE_T(\theta)/d\theta\).</p>

<h2 id="references">References</h2>
<ol class="bibliography"><li><span id="goodfellow2014">Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., &amp; Bengio, Y. (2014). Generative Adversarial Networks. <i>Communications of the ACM</i>, <i>63</i>(11), 139–144. https://arxiv.org/abs/1406.2661v1</span></li>
<li><span id="vaswani2017">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017). Attention Is All You Need. <i>Advances in Neural Information Processing Systems</i>, <i>2017-Decem</i>, 5999–6009. https://arxiv.org/abs/1706.03762v5</span></li>
<li><span id="rumelhart1986">Rumelhart, D. E., Hinton, G. E., &amp; Williams, R. J. (1986). Learning representations by back-propagating errors. <i>Nature</i>, <i>323</i>(6088), 533. https://doi.org/10.1038/323533a0</span></li>
<li><span id="hornik1989">Hornik, K., Stinchcombe, M., &amp; White, H. (1989). Multilayer feedforward networks are universal approximators. <i>Neural Networks</i>, <i>2</i>(5), 359. https://doi.org/10.1016/0893-6080(89)90020-8</span></li>
<li><span id="krizhevsky2012">Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks. <i>Communications of the ACM</i>, <i>60</i>(6), 84–90. https://doi.org/10.1145/3065386</span></li>
<li><span id="rabinowicz1951">Rabinowicz, E. (1951). The Nature of the Static and Kinetic Coefficients of Friction. <i>Journal of Applied Physics</i>, <i>22</i>(11), 1373–1379. https://doi.org/10.1063/1.1699869</span></li>
<li><span id="dokos1946">Dokos, S. J. (1946). Sliding Friction Under Extreme Pressures—1. <i>Journal of Applied Mechanics</i>, <i>13</i>(2), A148–A156. https://doi.org/10.1115/1.4009539</span></li>
<li><span id="nordhagen2023a">Nordhagen, E. M., Sveinsson, H. A., &amp; Malthe-Sørenssen, A. (2023). Diffusion-Driven Frictional Aging in Silicon Carbide. <i>Tribology Letters</i>, <i>71</i>(3), 95. https://doi.org/10.1007/s11249-023-01762-z</span></li>
<li><span id="bi2023">Bi, K., Xie, L., Zhang, H., Chen, X., Gu, X., &amp; Tian, Q. (2023). Accurate medium-range global weather forecasting with 3D neural networks. <i>Nature</i>, <i>619</i>(7970), 533–538. https://doi.org/10.1038/s41586-023-06185-3</span></li>
<li><span id="lillicrap2020">Lillicrap, T. P., Santoro, A., Marris, L., Akerman, C. J., &amp; Hinton, G. (2020). Backpropagation and the brain. <i>Nature Reviews Neuroscience</i>, <i>21</i>(6), 335–346. https://doi.org/10.1038/s41583-020-0277-3</span></li></ol>

<p>Feel free to drop a comment or question below if you have thoughts or experiences you’d like to share.</p>

<div class="signature">
    <img src="/assets/img/signature.png" alt="Signature" style="width: 50%;" />
</div>


      

      

    </div>
  </div>
</main>


  <footer>
  <div class="container-md beautiful-jekyll-footer">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
      
<ul class="list-inline text-center footer-links"><li class="list-inline-item">
    <a href="mailto:even.nordhagen@gmail.com" title="Email me">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">Email me</span>
   </a>
  </li><li class="list-inline-item">
    <a href="https://github.com/evenmn" title="GitHub">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">GitHub</span>
   </a>
  </li><li class="list-inline-item">
    <a href="https://linkedin.com/in/evenmarius.nordhagen" title="LinkedIn">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">LinkedIn</span>
   </a>
  </li><li class="list-inline-item">
    <a href="tel:4748043633" title="Phone">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fas fa-phone fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">Phone</span>
   </a>
  </li><li class="list-inline-item">
   <a href="https://orcid.org/0009-0005-3839-4011" title="ORCID">
     <span class="fa-stack fa-lg" aria-hidden="true">
       <i class="fas fa-circle fa-stack-2x"></i>
       <i class="fab fa-orcid fa-stack-1x fa-inverse"></i>
     </span>
     <span class="sr-only">ORCID</span>
   </a>
 </li><li class="list-inline-item">
    <a href="https://scholar.google.com/citations?user=even.nordhagen@gmail.com" title="Google Scholar">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fa fa-graduation-cap fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">Google Scholar</span>
    </a>
  </li></ul>


      
      <p class="copyright text-muted">
      
        © Even Nordhagen
        &nbsp;&bull;&nbsp;
      
      2025

      
        &nbsp;&bull;&nbsp;
        <span class="author-site">
          <a href="/">evennordhagen.com</a>
        </span>
      

      

      

      </p>
      
      </div>
    </div>
  </div>
</footer>


  
  
    
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin="anonymous"></script>


  
    
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


  
    
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


  



  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
      <script src="/assets/js/beautifuljekyll.js"></script>
    
  









</body>
</html>
